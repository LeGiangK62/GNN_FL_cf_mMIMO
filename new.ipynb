{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d78a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# from Models.GNN import IGCNet\n",
    "from Utils.data_gen import Generate_Input, create_graph\n",
    "from Utils.training import sr_loss_matrix, average_weights\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39f9c1",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8533e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_H = 8\n",
    "num_test = 20\n",
    "K = 5 # number of terminals\n",
    "M = 10 # number of access points\n",
    "B = 20 # Mhz\n",
    "D = 1 # km\n",
    "tau=10\n",
    "random_matrix = np.random.randn(tau, tau)\n",
    "U, S, V = np.linalg.svd(random_matrix)\n",
    "\n",
    "Hb = 15 # Base station height in m\n",
    "Hm = 1.65 # Mobile height in m\n",
    "f = 1900 # Frequency in MHz\n",
    "aL = (1.1 * np.log10(f) - 0.7) * Hm - (1.56 * np.log10(f) - 0.8)\n",
    "L = 46.3+33.9*np.log10(f)-13.82*np.log10(Hb)-aL\n",
    "\n",
    "power_f=0.2 # downlink power\n",
    "# Pd = power_f / 10 ** ((-203.975 + 10 * np.log10(20 * 10 ** 6) + 9) / 10) # normalized receive SNR\n",
    "Ther_noise = 20000000 * 10**(-17.4) * 10**-3\n",
    "Pd = 1/Ther_noise\n",
    "Pu=Pd\n",
    "\n",
    "d0=0.01 # km\n",
    "d1=0.05 # km\n",
    "\n",
    "N = 50\n",
    "\n",
    "R_cf_min = np.zeros(N)  # Cell Free\n",
    "R_cf_sum = np.zeros(N)\n",
    "R_cf_opt_min = np.zeros(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f3b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 4\n",
    "num_test = 2\n",
    "batchSize = 32\n",
    "num_rounds = 20\n",
    "\n",
    "num_epochs = 500\n",
    "lr = 1e-4\n",
    "step_size = 5\n",
    "gamma = 0.9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f097f8",
   "metadata": {},
   "source": [
    "## Create data loader for training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90bb56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_AP = M \n",
    "Beta_all, Phi_all = Generate_Input(num_train, tau, K, M, Pd, D=1, Hb=15, Hm=1.65, f=1900,\n",
    "                    var_noise=1, Pmin=0, seed=2017, d0=d0, d1=d1)\n",
    "train_data = create_graph(Beta_all, Phi_all)\n",
    "train_loader = [\n",
    "    DataLoader(train_data[i], batch_size=batchSize, shuffle=True)\n",
    "    for i in range(num_AP)\n",
    "]\n",
    "\n",
    "Beta_test, Phi_test = Generate_Input(num_test, tau, K, M, Pd, D=1, Hb=15, Hm=1.65, f=1900,\n",
    "                    var_noise=1, Pmin=0, seed=2017, d0=d0, d1=d1)\n",
    "test_data = create_graph(Beta_test, Phi_test)\n",
    "test_loader = [\n",
    "    DataLoader(test_data[i], batch_size=batchSize, shuffle=False)\n",
    "    for i in range(num_AP)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbd7caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channels = 32 # > 4\n",
    "num_gnn_layers = 2\n",
    "\n",
    "\n",
    "ap_dim = train_data[0][0]['AP'].x.shape[1]\n",
    "ue_dim = train_data[0][0]['UE'].x.shape[1]\n",
    "edge_dim = train_data[0][0]['down'].edge_attr.shape[1]\n",
    "tt_meta = [('UE', 'up', 'AP'), ('AP', 'down', 'UE')]\n",
    "dim_dict = {\n",
    "    'UE': ue_dim,\n",
    "    'AP': ap_dim,\n",
    "    'edge': edge_dim,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2e03c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.GNN import APHetNet\n",
    "\n",
    "model = APHetNet(\n",
    "    metadata=tt_meta,\n",
    "    dim_dict=dim_dict,\n",
    "    out_channels=hidden_channels,\n",
    "    num_layers=num_gnn_layers,\n",
    "    hid_layers=hidden_channels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb648ad",
   "metadata": {},
   "source": [
    "# Main trainining pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab1aeb",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8711a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.GNN import APHetNet\n",
    "from Utils.training import train, eval\n",
    "from Utils.synthetic_graph import return_graph, combine_graph\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "global_model = APHetNet(\n",
    "    metadata=tt_meta,\n",
    "    dim_dict=dim_dict,\n",
    "    out_channels=hidden_channels,\n",
    "    num_layers=num_gnn_layers,\n",
    "    hid_layers=hidden_channels\n",
    ").to(device)\n",
    "local_models, optimizers = [], []\n",
    "\n",
    "# Init every client model/optimizer\n",
    "for each_AP in range(num_AP):\n",
    "    model = APHetNet(\n",
    "        metadata=tt_meta,\n",
    "        dim_dict=dim_dict,\n",
    "        out_channels=hidden_channels,\n",
    "        num_layers=num_gnn_layers,\n",
    "        hid_layers=hidden_channels\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    local_models.append(model)\n",
    "    optimizers.append(optimizer)\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    # zip loaders to align batches across APs\n",
    "    for batches in zip(*train_loader):                       # sync step across APs\n",
    "        send_to_server = []\n",
    "        \n",
    "        for model, opt, batch in zip(local_models, optimizers, batches):\n",
    "            # Check batch here? something wrong?\n",
    "            model.eval()\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            x_dict, edge_dict, edge_index = model(batch)\n",
    "\n",
    "            send_to_server.append({\n",
    "                'num_graphs': batch.num_graphs,\n",
    "                \"AP\": x_dict['AP'].detach(),\n",
    "                \"edge_attr\": edge_dict['AP', 'down', 'UE'].detach(),\n",
    "                \"edge_index\": edge_index['AP', 'down', 'UE'].detach()}\n",
    "            )\n",
    "        \n",
    "    return_from_server = return_graph(send_to_server)\n",
    "    \n",
    "    for model, opt, batches, complements in zip(local_models, optimizers, train_loader, return_from_server):\n",
    "        model.train() \n",
    "        opt.zero_grad() \n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        for batch, complement in zip(batches, complements):\n",
    "            batch = batch.to(device)\n",
    "            complement = complement.to(device)\n",
    "            modified_batch = combine_graph(batch, complement) # incorrect?\n",
    "            break\n",
    "            \n",
    "        # local_loss = train(batches, complements, model, opt)\n",
    "        \n",
    "        \n",
    "        # local_loss.backward()\n",
    "        # opt.step()\n",
    "\n",
    "    # # --- FedAvg (optional, by sample count) ---\n",
    "    # local_weights = [m.state_dict() for m in local_models]\n",
    "    # sizes = [len(dl.dataset) for dl in train_loader]\n",
    "    # new_state = average_weights(local_weights, sizes)\n",
    "    # global_model.load_state_dict(new_state)\n",
    "    \n",
    "    # # Update client models\n",
    "    # for m in local_models: \n",
    "    #     m.load_state_dict(global_model.state_dict())\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f13b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graph = batch.num_graphs\n",
    "x_dict, edge_dict, edge_index = model(modified_batch)\n",
    "graphData, nodeFeatDict, edgeAttrDict = modified_batch, x_dict, edge_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985a1f5",
   "metadata": {},
   "source": [
    "## Loss function test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graphs = graphData.num_graphs\n",
    "num_UE = graphData['UE'].x.shape[0]//num_graphs\n",
    "num_AP = graphData['AP'].x.shape[0]//num_graphs\n",
    "pilot_matrix = graphData['UE'].x.reshape(num_graphs, num_UE, -1)\n",
    "large_sacle_fading = edgeAttrDict[('AP', 'down', 'UE')][:,:-1].reshape(num_graphs, num_AP, num_UE)\n",
    "power = edgeAttrDict[('AP', 'down', 'UE')][:,:-1].reshape(num_graphs, num_AP, num_UE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3944db00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroDataBatch(\n",
       "  AP={\n",
       "    x=[4, 1],\n",
       "    batch=[4],\n",
       "    ptr=[5],\n",
       "  },\n",
       "  UE={\n",
       "    x=[20, 10],\n",
       "    batch=[20],\n",
       "    ptr=[5],\n",
       "  },\n",
       "  (AP, down, UE)={\n",
       "    edge_index=[2, 20],\n",
       "    edge_attr=[20, 1],\n",
       "  },\n",
       "  (UE, up, AP)={\n",
       "    edge_index=[2, 20],\n",
       "    edge_attr=[20, 1],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modified_batch\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4f737",
   "metadata": {},
   "source": [
    "# Main Training Old Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddb858",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_AP = M \n",
    "Beta_all, Phi_all = Generate_Input(num_train, tau, K, M, Pd, D=1, Hb=15, Hm=1.65, f=1900,\n",
    "                    var_noise=1, Pmin=0, seed=2017, d0=d0, d1=d1)\n",
    "train_data = create_graph(Beta_all, Phi_all)\n",
    "train_loader = [\n",
    "    DataLoader(train_data[i], batch_size=batchSize, shuffle=True)\n",
    "    for i in range(num_AP)\n",
    "]\n",
    "\n",
    "Beta_test, Phi_test = Generate_Input(num_test, tau, K, M, Pd, D=1, Hb=15, Hm=1.65, f=1900,\n",
    "                    var_noise=1, Pmin=0, seed=2017, d0=d0, d1=d1)\n",
    "test_data = create_graph(Beta_test, Phi_test)\n",
    "test_loader = [\n",
    "    DataLoader(test_data[i], batch_size=batchSize, shuffle=False)\n",
    "    for i in range(num_AP)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN_FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
