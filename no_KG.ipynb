{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65385575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# from Models.GNN import IGCNet\n",
    "from Utils.training import sr_loss_matrix, average_weights\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f8227",
   "metadata": {},
   "source": [
    "# Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e000d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_H = 8\n",
    "num_test = 20\n",
    "K = 5 # number of terminals\n",
    "M = 10 # number of access points\n",
    "B = 20 # Mhz\n",
    "D = 1 # km\n",
    "tau=10\n",
    "random_matrix = np.random.randn(tau, tau)\n",
    "U, S, V = np.linalg.svd(random_matrix)\n",
    "\n",
    "Hb = 15 # Base station height in m\n",
    "Hm = 1.65 # Mobile height in m\n",
    "f = 1900 # Frequency in MHz\n",
    "aL = (1.1 * np.log10(f) - 0.7) * Hm - (1.56 * np.log10(f) - 0.8)\n",
    "L = 46.3+33.9*np.log10(f)-13.82*np.log10(Hb)-aL\n",
    "\n",
    "power_f=0.2 # downlink power\n",
    "rho_p, rho_d = power_f, power_f\n",
    "\n",
    "# Pd = power_f / 10 ** ((-203.975 + 10 * np.log10(20 * 10 ** 6) + 9) / 10) # normalized receive SNR\n",
    "Ther_noise = 20000000 * 10**(-17.4) * 10**-3\n",
    "Pd = 1/Ther_noise\n",
    "Pu=Pd\n",
    "\n",
    "d0=0.01 # km\n",
    "d1=0.05 # km\n",
    "\n",
    "N = 50\n",
    "\n",
    "R_cf_min = np.zeros(N)  # Cell Free\n",
    "R_cf_sum = np.zeros(N)\n",
    "R_cf_opt_min = np.zeros(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b13b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 4\n",
    "num_test = 2\n",
    "batchSize = 32\n",
    "num_rounds = 20\n",
    "\n",
    "num_epochs = 500\n",
    "lr = 1e-4\n",
    "step_size = 5\n",
    "gamma = 0.9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386217ba",
   "metadata": {},
   "source": [
    "# Create data loader for training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "013dfd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.data_gen import Generate_Input, create_graph\n",
    "\n",
    "num_AP = M \n",
    "Beta_all, Phi_all = Generate_Input(num_train, tau, K, M, Pd, D=1, Hb=15, Hm=1.65, f=1900,\n",
    "                    var_noise=1, Pmin=0, seed=2017, d0=d0, d1=d1)\n",
    "train_data = create_graph(Beta_all, Phi_all, 'het')\n",
    "train_loader = [\n",
    "    DataLoader(train_data[i], batch_size=batchSize, shuffle=True)\n",
    "    for i in range(num_AP)\n",
    "]\n",
    "\n",
    "Beta_test, Phi_test = Generate_Input(num_test, tau, K, M, Pd, D=1, Hb=15, Hm=1.65, f=1900,\n",
    "                    var_noise=1, Pmin=0, seed=2017, d0=d0, d1=d1)\n",
    "test_data = create_graph(Beta_test, Phi_test, 'het')\n",
    "test_loader = [\n",
    "    DataLoader(test_data[i], batch_size=batchSize, shuffle=False)\n",
    "    for i in range(num_AP)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dbcf6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channels = 32 # > 4\n",
    "num_gnn_layers = 2\n",
    "\n",
    "\n",
    "ap_dim = train_data[0][0]['AP'].x.shape[1]\n",
    "ue_dim = train_data[0][0]['UE'].x.shape[1]\n",
    "edge_dim = train_data[0][0]['down'].edge_attr.shape[1]\n",
    "tt_meta = [('UE', 'up', 'AP'), ('AP', 'down', 'UE')]\n",
    "dim_dict = {\n",
    "    'UE': ue_dim,\n",
    "    'AP': ap_dim,\n",
    "    'edge': edge_dim,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99d459b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.GNN import APHetNet\n",
    "\n",
    "model = APHetNet(\n",
    "    metadata=tt_meta,\n",
    "    dim_dict=dim_dict,\n",
    "    out_channels=hidden_channels,\n",
    "    num_layers=num_gnn_layers,\n",
    "    hid_layers=hidden_channels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d35ce82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.GNN import APHetNet\n",
    "from Utils.training import train, eval, package_calculate\n",
    "from Utils.synthetic_graph import return_graph, combine_graph\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "global_model = APHetNet(\n",
    "    metadata=tt_meta,\n",
    "    dim_dict=dim_dict,\n",
    "    out_channels=hidden_channels,\n",
    "    num_layers=num_gnn_layers,\n",
    "    hid_layers=hidden_channels\n",
    ").to(device)\n",
    "local_models, optimizers = [], []\n",
    "\n",
    "# Init every client model/optimizer\n",
    "for each_AP in range(num_AP):\n",
    "    model = APHetNet(\n",
    "        metadata=tt_meta,\n",
    "        dim_dict=dim_dict,\n",
    "        out_channels=hidden_channels,\n",
    "        num_layers=num_gnn_layers,\n",
    "        hid_layers=hidden_channels\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    local_models.append(model)\n",
    "    optimizers.append(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70bdca",
   "metadata": {},
   "source": [
    "# Main Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d36441",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 20\n",
    "\n",
    "num_client = num_AP \n",
    "num_epochs = 500\n",
    "eval_round = num_rounds//10\n",
    "\n",
    "log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e44fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Federated Learning with 10 clients for 20 rounds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fed_avg() missing 1 required positional argument: 'client_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[220], line 36\u001b[0m\n\u001b[1;32m     31\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m num_client\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# print(f\"Round {round+1}: Average local training loss = {avg_loss:.6f}\")\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m## 3. Update global models\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m global_weights \u001b[38;5;241m=\u001b[39m \u001b[43mfed_avg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Broadcast updated global weights to all clients\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m local_models:\n",
      "\u001b[0;31mTypeError\u001b[0m: fed_avg() missing 1 required positional argument: 'client_weights'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from Utils.training import loss_function, fl_train, fl_eval, get_global_info, distribute_global_info, average_weights\n",
    "\n",
    "\n",
    "print(f\"Starting Federated Learning with {num_client} clients for {num_rounds} rounds\")\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    # print(f\"\\n=== Federated Round {round+1}/{num_rounds} ===\")\n",
    "    \n",
    "    ## 1.Exchange global information\n",
    "    send_to_server = get_global_info(\n",
    "        train_loader, local_models, optimizers,\n",
    "        tau=tau, rho_p=power_f, rho_d=power_f\n",
    "    )\n",
    "    response_all = distribute_global_info(send_to_server)\n",
    "    \n",
    "    \n",
    "    ## 2. Training Local models    \n",
    "    local_weights = []\n",
    "    total_loss = 0.0\n",
    "    for model, opt, batches , responses_ap in zip(local_models, optimizers, train_loader, response_all):\n",
    "        model.train() \n",
    "        opt.zero_grad() \n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = fl_train(\n",
    "                batches, responses_ap, model, opt,\n",
    "                tau=tau, rho_p=power_f, rho_d=power_f, num_antenna=N\n",
    "            )\n",
    "        local_weights.append(copy.deepcopy(model.state_dict()))\n",
    "        total_loss += train_loss\n",
    "    avg_loss = total_loss / num_client\n",
    "    # print(f\"Round {round+1}: Average local training loss = {avg_loss:.6f}\")\n",
    "\n",
    "\n",
    "    ## 3. Update global models\n",
    "    global_weights = average_weights(glolocal_weights)\n",
    "\n",
    "    # Broadcast updated global weights to all clients\n",
    "    for model in local_models:\n",
    "        model.load_state_dict(global_weights)\n",
    "\n",
    "\n",
    "    ## 4. Exchange global eval information\n",
    "    # print(\"Evaluating global model(s)...\")\n",
    "    send_to_server_eval = get_global_info(\n",
    "        test_loader, local_models, optimizers,\n",
    "        tau=tau, rho_p=power_f, rho_d=power_f\n",
    "    )\n",
    "    response_all_eval = distribute_global_info(send_to_server_eval)\n",
    "    total_eval_rate = 0.0\n",
    "    for client_idx, (model, loader, responses) in enumerate(zip(local_models, test_loader, response_all_eval)):\n",
    "        model.eval() \n",
    "        for epoch in range(num_epochs):\n",
    "            eval_metrics = fl_eval(\n",
    "                loader, responses, model,\n",
    "                tau=tau, rho_p=power_f, rho_d=power_f, num_antenna=N\n",
    "            )\n",
    "        total_eval_rate += eval_metrics\n",
    "    total_eval_rate = total_eval_rate/num_client\n",
    "        # print(f\"Client {client_idx}: {eval_metrics}\")\n",
    "    \n",
    "    if round%eval_round==0:\n",
    "        print(f\"Round {round+1:02d}/{num_rounds}: Avg Training Rate = {-avg_loss:.6f} | Avg Eval rate = {total_eval_rate:.6f}\")\n",
    "            \n",
    "    log.append({\n",
    "        \"round\": round + 1,\n",
    "        \"train_loss\": avg_loss,\n",
    "        \"eval\": eval_metrics\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2f29e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n",
      "Final Round | Avg Train Loss: -2.369643 | Avg Eval: 0.02677050791680813\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Final Round | Avg Train Loss: {log[-1]['train_loss']:.6f} | Avg Eval: {log[-1]['eval']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1598b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "devcie = batch['UE'].x.device\n",
    "dtype = batch['UE'].x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7a2a1972",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_antenna = N\n",
    "\n",
    "device \n",
    "\n",
    "num_graphs = batch.num_graphs\n",
    "num_UEs = batch['UE'].x.shape[0]//num_graphs\n",
    "num_APs = batch['AP'].x.shape[0]//num_graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d7e7dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.training import component_calculate, variance_calculate\n",
    "\n",
    "pilot_matrix = batch['UE'].x.reshape(num_graphs, num_UEs, -1)\n",
    "large_scale = batch['AP','down','UE'].edge_attr.reshape(num_graphs, num_APs, num_UEs)\n",
    "\n",
    "power = x_dict['UE'].reshape(num_graphs, num_UEs, -1)\n",
    "power_matrix = power[:,:,-1][:, None, :]\n",
    "\n",
    "channel_variance = variance_calculate(large_scale, pilot_matrix, tau, rho_p)\n",
    "\n",
    "DS_k, PC_k, UI_k = component_calculate(power_matrix, channel_variance, large_scale, pilot_matrix, rho=rho_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4133bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_DS = [DS_k] + [r['DS'] for r in response]\n",
    "all_PC = [PC_k] + [r['PC'] for r in response]\n",
    "all_UI = [UI_k] + [r['UI'] for r in response]\n",
    "\n",
    "all_DS = torch.cat(all_DS, dim=1)\n",
    "all_PC = torch.cat(all_PC, dim=1)   # \n",
    "all_UI = torch.cat(all_UI, dim=1)   # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d1d518d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.3231, device='cuda:0', grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from Utils.training import rate_from_component\n",
    "rate = rate_from_component(all_DS, all_PC, all_UI, num_antenna)\n",
    "min,_ = torch.min(rate, dim=1)\n",
    "print(-torch.mean(min))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261e788",
   "metadata": {},
   "source": [
    "# Testing calculating DS, PC, UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46d4c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = edge_index['AP', 'down', 'UE']\n",
    "k = 3\n",
    "m = 0\n",
    "s = 3\n",
    "tmp = s * num_APs * num_UEs + m * num_UEs + k\n",
    "idx = idx[:, tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f589379b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0207], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['AP', 'down', 'UE'].edge_attr[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "101c7408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0207, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largeScale[s, m, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f13a5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graphs = batch.num_graphs\n",
    "num_UEs = x_dict['UE'].shape[0] // num_graphs\n",
    "num_APs = x_dict['AP'].shape[0] // num_graphs\n",
    "ue_feature = x_dict['UE'].reshape(num_graphs, num_UEs, -1)\n",
    "power = ue_feature[:,:, -1][:,None,:]\n",
    "phiMatrix = ue_feature[:,:, :-1]\n",
    "\n",
    "largeScale = batch['AP', 'down', 'UE'].edge_attr.reshape(num_graphs, num_APs, num_UEs)\n",
    "\n",
    "# channelVariance = variance_calculate(largeScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f842b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating DS PC UI\n",
    "rho = power_f\n",
    "num_graphs = 3\n",
    "num_AP = M\n",
    "num_UE = K\n",
    "tau = tau\n",
    "power = torch.rand(num_graphs, num_AP, num_UE)\n",
    "channelVariance = torch.rand(num_graphs, num_AP, num_UE)\n",
    "largeScale = torch.rand(num_graphs, num_AP, num_UE)\n",
    "phiMatrix = torch.rand(num_graphs, num_UE, tau)\n",
    "\n",
    "rho_p = power_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a888d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674b7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "319675dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denom = torch.zeros(num_graphs, num_AP, num_UE)\n",
    "for s in range(num_graphs):\n",
    "    for k in range(num_UE):\n",
    "        for m in range(num_AP):\n",
    "            term1 = 0\n",
    "            for k_prime in range(num_UE):\n",
    "                term1 += largeScale[s,m,k_prime] * tmp[s,k_prime, k]\n",
    "            denom[s,m,k] = tau * rho_p * term1 + 1\n",
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a8a3320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2398e-05)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(denom - denom_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a836618",
   "metadata": {},
   "outputs": [],
   "source": [
    "pilotContamination = torch.bmm(\n",
    "    phiMatrix,\n",
    "    phiMatrix.transpose(1, 2),\n",
    ").abs()\n",
    "\n",
    "DS_all = torch.zeros(num_graphs, num_AP, num_UE)\n",
    "PC_all = torch.zeros(num_graphs, num_AP, num_UE, num_UE)\n",
    "UI_all = torch.zeros(num_graphs, num_AP, num_UE, num_UE)\n",
    "\n",
    "for s in range(num_graphs):\n",
    "    for m in range(num_AP):\n",
    "        for k in range(num_UE):\n",
    "            DS_all[s, m, k] = torch.sqrt(rho * power[s,m,k]) *  channelVariance[s,m,k]\n",
    "            for k_prime in range(num_UE):\n",
    "                if k_prime == k: continue\n",
    "                PC_all[s,m,k_prime,k] = torch.sqrt(rho * power[s,m,k_prime]) * channelVariance[s,m,k_prime]\n",
    "                PC_all[s,m,k_prime,k] = PC_all[s,m,k_prime,k] * largeScale[s,m,k] / largeScale[s,m,k_prime]\n",
    "                PC_all[s,m,k_prime,k] = PC_all[s,m,k_prime,k] * pilotContamination[s,k_prime,k]\n",
    "\n",
    "                UI_all[s,m,k_prime,k] = rho * power[s,m,k_prime] * channelVariance[s,m,k_prime] * largeScale[s,m,k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "79ecb40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.training import package_calculate\n",
    "DS_all_matrix, PC_all_matrix, UI_all_matrix = package_calculate(power, channelVariance, largeScale, phiMatrix, power_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7ce06889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(-1.5063e-06)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(DS_all_matrix - DS_all))\n",
    "print(torch.sum(PC_all_matrix - PC_all))\n",
    "print(torch.sum(UI_all_matrix - UI_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8a14c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.7123, 3.0449, 3.5054, 2.7120, 5.6616],\n",
       "         [3.0449, 2.1908, 1.8349, 1.5801, 2.3079],\n",
       "         [3.5054, 1.8349, 2.2462, 1.4913, 2.9244],\n",
       "         [2.7120, 1.5801, 1.4913, 1.6840, 2.3059],\n",
       "         [5.6616, 2.3079, 2.9244, 2.3059, 5.1982]],\n",
       "\n",
       "        [[4.7962, 3.7576, 2.2543, 4.0618, 2.6975],\n",
       "         [3.7576, 4.3708, 2.4290, 3.9286, 2.3960],\n",
       "         [2.2543, 2.4290, 2.1171, 1.7512, 1.6905],\n",
       "         [4.0618, 3.9286, 1.7512, 5.2153, 2.9763],\n",
       "         [2.6975, 2.3960, 1.6905, 2.9763, 3.0562]],\n",
       "\n",
       "        [[3.1328, 2.9414, 2.0053, 2.3504, 1.5182],\n",
       "         [2.9414, 4.1403, 2.7787, 2.5556, 1.6181],\n",
       "         [2.0053, 2.7787, 2.7678, 1.9248, 1.1849],\n",
       "         [2.3504, 2.5556, 1.9248, 2.7166, 1.4954],\n",
       "         [1.5182, 1.6181, 1.1849, 1.4954, 1.3532]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilotContamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e2ed3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 5, 5])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "().shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN_FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
